Excelente! üëè Como podemos ver, `StandardScaler` transforma o conjunto de dados para que suas vari√°veis se aproximem de uma distribui√ß√£o normal, para que todos os dados tenham um [desvio padr√£o](https://pt.wikipedia.org/wiki/Desvio_padr%C3%A3o) da mesma ordem. Desta forma, cada dado nos dar√° uma ideia de quantos desvios da m√©dia est√° aquele ponto.

Esses tipos de procedimentos s√£o muito importantes quando se faz qualquer tipo de an√°lise de dados, e n√£o apenas quando se trabalha com dist√¢ncias euclidianas. Vamos imaginar que temos que analisar a trajet√≥ria profissional de duas pessoas, para fazer uma sele√ß√£o de emprego. :page_with_curl: A priori, seria l√≥gico pensar em basear essa sele√ß√£o no curr√≠culo dessas pessoas, certo?

No entanto, o curr√≠culo n√£o nos d√° uma imagem completa das habilidades de uma pessoa. Por exemplo, n√£o nos permite saber sua capacidade de trabalhar em equipe ou sua capacidade de realizar mais de uma tarefa ao mesmo tempo, etc. Que peso estamos dando ent√£o a essas outras caracter√≠sticas? Estamos subestimando ou supervalorizando as habilidades das pessoas? E as pessoas que n√£o t√™m as mesmas possibilidades de completar o curr√≠culo? Isso os torna menos capazes para o trabalho?

Em outras palavras, como  ilustra [este conto](https://www.hypeness.com.br/2015/05/quadrinho-resume-o-porque-de-a-historia-de-que-todo-mundo-tem-as-mesmas-chances-nao-e-tao-verdadeira-assim-2/) de [Toby Morris](https://en.wikipedia.org/wiki/Toby_Morris_(cartoonist)) √© que √© necess√°rio dimensionar os dados para que todos os recursos sejam igualmente importantes e nenhum seja dominado por outro.
